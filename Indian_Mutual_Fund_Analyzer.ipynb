{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# --- Import Libraries ---\n\n# Pandas to handle the data\nimport pandas as pd\n\n# For checking URL and HTTP errors\nfrom urllib.error import URLError, HTTPError","metadata":{"_uuid":"c8f5bf26-b2cf-4d21-ae4a-a504b9794749","_cell_guid":"e4c557ed-5e21-43bb-928c-a34d1043b956","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Global Variables","metadata":{}},{"cell_type":"code","source":"# --- GLOBAL VARIABLES ---\n\n# AMFI Site URL that holds a CSV with all mutual funds\nAMFI_SCHEME_URL = 'https://portal.amfiindia.com/DownloadSchemeData_Po.aspx?mf=0'\nAMFI_SCHEME_LATEST_NAV_URL = 'https://www.amfiindia.com/spages/NAVAll.txt'","metadata":{"_uuid":"e0d3c932-ed98-4b56-a813-b8e24f0b7d50","_cell_guid":"efe42dfd-1b95-4a18-9655-8a3ddddf3138","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fetch Mutual Fund Scheme List","metadata":{"_uuid":"b542d708-5ff1-43a4-9695-623f05a6d388","_cell_guid":"91aabd30-6e68-4b8e-b62d-7e75800edca3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Changing the column names to a more uniform and descriptive names\nmf_col_names = [\n    'AMC', \n    'Scheme_Code', \n    'Scheme_Name', \n    'Scheme_Type', \n    'Scheme_Category', \n    'Scheme_NAV_Name', \n    'Scheme_Min_Amt', \n    'Launch_Date', \n    'Closure_Date', \n    'ISIN_Div_Payout/Growth/Div_Reinvestment']\n\n# --- Read Data ---\ntry:\n    # Reading the URL, updating col names and datatypes\n    mf_scheme_df = pd.read_csv(\n        AMFI_SCHEME_URL, \n        names = mf_col_names, \n        # dtype = mf_scheme_dtypes, takes a dict of col:dtype \n        header = 0\n    )\n    print(\"üìñ Successfully read scheme data from AMFI Website!\")\n    # Row and column count \n    print(f\"üìã Total Rows & Columns: {mf_scheme_df.shape}\")\nexcept (URLError, HTTPError) as e:\n    # Exception to handle URL and HTTP errors\n    print(f\"üõú Error reading CSV from URL: {e}.\")\nexcept Exception as e:\n    # Exception to catch all other errors\n    print(f\"‚ùå Error occurred while reading CSV: {e}.\")","metadata":{"_uuid":"bc30728d-9ca5-486f-bb02-fe8b91c2c577","_cell_guid":"4e806ab9-de1c-48e1-b80e-adc63f08a481","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fetch Latest NAV Data From AMFI","metadata":{"_uuid":"3f7c97c9-f9a6-4c81-a809-bcae6df5ba20","_cell_guid":"1e98141a-521f-4c1f-8431-a234ff79902e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Changing the column names to a more uniform and descriptive names\nnav_col_names = [\n    'Scheme_Code',\n    'ISIN_Div_Payout/Growth',\n    'ISIN_Div_Reinvestment',\n    'Scheme_Name', \n    'NAV', \n    'Latest_NAV_Date'\n]\n\n# --- Read Data ---\ntry:\n    # Getting the latest NAV(Net Asset Value)\n    latest_nav_df = pd.read_csv(\n        AMFI_SCHEME_LATEST_NAV_URL,\n        names = nav_col_names,\n        header = 0, \n        sep = ';',    \n    )\n    print(\"üìä Successfully read latest NAV data from AMFI Website!\")\n    # Row and column count \n    print(f\"üìã Total Rows & Columns: {latest_nav_df.shape}\")\nexcept (URLError, HTTPError) as e:\n    # Exception to handle URL and HTTP errors\n    print(f\"üõú Error reading CSV from URL: {e}.\")\nexcept Exception as e:\n    # Exception to catch all other errors\n    print(f\"‚ùå Error occurred while reading TXT: {e}.\")\n\n# --- Sort & Filter Data ---\ntry:\n    # Sort the values by scheme code in ascending order and updating the original df\n    latest_nav_df.sort_values(\n        'Scheme_Code', ascending = True, inplace = True)\n    # Drop NaN, if Scheme name, nav and nav date are NaN as the TXT we are importing has these weird headings of AMC and fund categories\n    latest_nav_df.dropna(\n        subset = ['Scheme_Name', 'NAV','Latest_NAV_Date'], \n        inplace = True)\n    print(\"‚úÖ Successfully removed NaN from latest_nav_df.\")\n    # Row and column count \n    print(f\"üÜï Updated Rows & Columns: {latest_nav_df.shape}\")\nexcept Exception as e:\n    # Exception to catch all other errors\n    print(f\"‚ùå Error occured while sorting scheme code/dropping NaN.\")","metadata":{"_uuid":"6d515ef0-87a9-4a87-8ad2-a8807aef2e6c","_cell_guid":"ff6df6ff-8c47-497d-b5b8-c3a9654eb069","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Type Conversion Function","metadata":{}},{"cell_type":"code","source":"# Function to convert the dataframe column dtypes (not a dataframe copy)\n# Need to import Pandas for this function to work!\n\nprint(\"‚è≥ Defining data type conversion function...\")\n\n\ndef data_type_conversion (input_dict, input_df, df_name):\n    \"\"\"\n    Converts dataframe columns to various (int, float, date/datetime, category and string) data types.\n\n    Args:\n        input_dict(dict): Key-Value pairs of 'col': 'dtype' to convert.\n        input_df(dataframe): Dataframe you want the changes to be made.\n        df_name(string): Pass the name of the Dataframe as a string for logs.\n\n    Returns:\n        Nothing returned, data type conversions are made to the passed dataframe(input_df)\n    \"\"\"\n\n    print(f\"üîÄ Sarting data type conversion for the dataframe: {df_name}.\")\n    \n    # --- Loop over the dict's items ---\n    for col, dtype in input_dict.items():\n        # --- Check if the column actually exists in the dataframe before changing data type ---\n        if col in input_df.columns:\n            print(f\"  üö© Attempting to convert '{col}' to type: '{dtype}'.\")\n            # Try-except for error handling\n            try:\n                # --- Apply conversion based on the dtype string from the dictionary ---\n                if dtype == 'int':\n                    # pd.to_numeric(errors='coerce') handles the dirty work of converting non-numeric garbage to NaN\n                    # .astype(dtype) comes after to enforce the specific target numeric type (float or the special Int64 that handles NaNs for integers) that you originally requested\n                    input_df[col] = pd.to_numeric(input_df[col], errors = 'coerce').astype('Int64')\n                elif dtype == 'float':\n                    # Coerce to numeric first, then ensure float type\n                    input_df[col] = pd.to_numeric(input_df[col], errors = 'coerce').astype('float')\n                elif dtype == 'date' or dtype == 'datetime':\n                    input_df[col] = pd.to_datetime(input_df[col], errors = 'coerce')\n                elif dtype == 'category':\n                    input_df[col] = input_df[col].astype('category')\n                elif dtype ==  'string':\n                    input_df[col] = input_df[col].astype('string')\n                else:\n                    print(f\"    üü® Warning: Unknown dtype '{dtype}' specified for column '{col}'. Could not attempt conversion.\")\n\n                print(f\"  ‚úÖ Successfully converted '{col}' to ''{input_df[col].dtype}''\")\n            except Exception as e:\n                print(f\"  ‚ùå Error converting column '{col}' to ''{dtype}'', Error: {e}\")\n        else:\n            print(f\"üü® Warning: '{col}' does not exists in '{df_name}' dataframe.\")\n    \n    # --- Data conversion done ---\n    print(f\"‚úÖ Finished data conversion for dataframe: {df_name}.\")\n\nprint(\"‚úÖ Defined data type conversion function.\")","metadata":{"_uuid":"6717175d-3abd-41ae-bed7-ac5dcbe8cb2e","_cell_guid":"8fd08ce9-f8ce-4999-b87d-c4d3ef5648a6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Process Data (Data Type Conversion)\n1. Convert categorical values to 'category' dtype.\n2. Convert dated columns to 'datetime' dtype.\n3. Convert numerical columns to 'Int64' and 'float' based on the data.","metadata":{"_uuid":"197d62f5-3bd4-4e04-8850-ae718280bd08","_cell_guid":"9c87c231-3e14-48dc-8a7d-af184bea3926","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# --- Data Type Conversion ---\n\n# Converting to 'category' datatype will reduce the memory and increase the speed of queries on the dataframe\nmf_scheme_dtypes = {\n    'AMC': 'category',\n    'Scheme_Code': 'int',\n    'Scheme_Type': 'category',\n    'Scheme_Category': 'category',\n    'Launch_Date': 'datetime', \n    'Closure_Date': 'datetime'\n}\n\n# Call the function to convert the columns of mf_scheme_df\ndata_type_conversion(mf_scheme_dtypes, mf_scheme_df, 'mf_scheme_df')\n\n\n# Dictionary of 'Col' : 'dtype' to convert the columns to a different dtype\nnav_dtypes = {\n    'Scheme_Code': 'int',\n    'NAV': 'float',\n    'Latest_NAV_Date': 'datetime'\n}\n\n# Call the function to convert the columns of latest_nav_df\ndata_type_conversion(nav_dtypes, latest_nav_df, 'latest_nav_df')\n\n\n# # Data Type conversion for merged_df\n# merged_dtypes = {\n    \n# }","metadata":{"_uuid":"69876cfd-0a22-4d0d-a4c8-7280d3b2c649","_cell_guid":"787feb08-cb99-4dfa-97ec-fb89c0234f4b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Merge Scheme Data & Latest NAV Data","metadata":{}},{"cell_type":"code","source":"print(\"‚è≥ Merging scheme data & latest NAV data...\")\n\n# Merge MF scheme data and latest NAV sata fetched from AMFI into a single dataframe\nmerged_df = pd.merge(\n    mf_scheme_df, \n    latest_nav_df, \n    # INNER JOIN on Scheme_Code column, we fetch the common records from both mf_scheme_df and latest_nav_df\n    on = 'Scheme_Code',\n    how = 'inner'\n)\n\nprint(\"‚úÖ Sucessfull merged scheme and NAV data.\")\n\n# Row and column count \nprint(f\"üìã Total Rows & Columns: {merged_df.shape}\")\n\n# --- Clean DataFrame ---\n\ntry:\n    # Drop duplicate columns\n    cols_to_drop = ['ISIN_Div_Payout/Growth/Div_Reinvestment', 'Scheme_Name_y']\n    \n    merged_df.drop(\n        labels = cols_to_drop,\n        axis = 'columns',\n        inplace = True\n    )\n    \n    # A dictionary of 'old_col':'new_col' to map column names from old to new\n    merged_mapper = {'Scheme_Name_x': 'Scheme_Name'}\n    # Rename column Scheme_Name_x to Scheme_Name\n    merged_df.rename(columns = merged_mapper, inplace = True)\n    \n    # Set index to Scheme_Code for faster queries on the dataframe\n    merged_df.set_index('Scheme_Code', inplace = True)\n    \n    # Sort the DataFrame by Scheme_Code(Index) for greater performace\n    merged_df.sort_index(ascending = True, inplace = True)\n\n    print(\"‚úÖ Sucessfully dropped columns, renamed columns, set and sorted index.\")\n\n    # Row and column count \n    print(f\"üÜï Updated Rows & Columns after cleaning: {merged_df.shape}\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Unable to clean the merged dataframe: {e}\")","metadata":{"_uuid":"c9d4e68c-5784-4ca3-921e-5a471e9e1ccb","_cell_guid":"1d55f534-2059-4723-ab41-58064dea36d3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Handling Data in merged_df","metadata":{}},{"cell_type":"code","source":"# Null Latest_NAV_Date after joining mf_scheme_df and latest_nav_df\nmerged_df['Latest_NAV_Date'].isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop the rows with no Latest_NAV_Date i.e schemes that are not being updated daily\n# Get rid of them for a smaller dataframe\ndf = merged_df.dropna(subset=['Latest_NAV_Date'])\ndf.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fetching Historical NAV (Work in progress)","metadata":{"_uuid":"2d59b8be-8731-4112-8792-38f38cb4e0c7","_cell_guid":"955572c4-59d0-49a4-9687-ca522666d3cc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Installing mftool to fetch mutual fund data\n!pip install mftool --quiet\n\n# Importing Mftool, and calling API function calls with mf.function()\nfrom mftool import Mftool\nmf = Mftool()","metadata":{"_uuid":"5d537f30-2512-41aa-b21f-0881e4c715ff","_cell_guid":"0d4ad4ce-ff4e-4f58-ab53-f8dc29e72b57","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#\ndef get_historical_nav_data (scheme_code):\n    \"\"\"\n    Fetches historical NAV data from Mftool library into a dataframe\n    Args:\n        scheme_code(int): \n    Return:\n    \n    \"\"\"\n\n    # --- Fetch Data ---\n\n    # Call the .get_scheme_historical_nav('scheme_code')\n    hist_nav_df = mf.get_scheme_historical_nav(scheme_code, as_Dataframe=True)\n\n    # --- Clean DataFrame ---\n\n    # Rename dataframe index from 'date' to 'NAV_Date'\n    hist_nav_df.index.name = 'NAV_Date'\n\n    # Mapper to map old column names to new column names\n    hist_mapper = {\n        'nav': 'NAV',\n        'dayChange': 'Daily_Change'\n    }\n\n    # Rename column names\n    hist_nav_df.rename(columns = hist_mapper, inplace = True)\n\n    # --- Handle Data ---\n\n    # Converting the index(NAV_Date) from object to datetime for better query performance \n    hist_nav_df.index = pd.to_datetime(\n        hist_nav_df.index, \n        format = '%d-%m-%Y', # Format to expect\n        errors = 'coerce')\n\n    # Dict to pass into data type conversion function\n    hist_nav_dtypes = {\n        'NAV': 'float'\n    }\n    \n    # Call data type conversion function and passing the dict(with col and dtype), dataframe, dataframe name as a string(for logs)\n    data_type_conversion(hist_nav_dtypes, hist_nav_df, 'hist_nav_df')\n\n    return hist_nav_df","metadata":{"_uuid":"2a61747b-03c9-489a-bb01-7f0214bc6fdd","_cell_guid":"eb994b4a-1db5-4ff0-86ae-0361461d2c7c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Testing Historical NAV Data","metadata":{}},{"cell_type":"code","source":"# Test\ncode = 101525\n\nnew_df = get_historical_nav_data(code)\nnew_df.info()\n\n# hist_nav_df = mf.get_scheme_historical_nav(code, as_Dataframe=True)\n# hist_nav_df.info()","metadata":{"_uuid":"cd684197-a931-441c-98f3-cf8ddc891c6f","_cell_guid":"33b04f73-d5da-4aee-b412-9e8650c1f737","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}